aliases: 蒸馏
created: 20250304051525220
creator: miRoox
modified: 20250304063440395
modifier: miRoox
tags: TODO
title: 大语言模型蒸馏
tmap.id: 34f57285-4961-4487-9b74-99dd6a72c544
type: text/vnd.tiddlywiki

''蒸馏'' (Distillation) 是一种将用于将[[大型语言模型|大语言模型]]知识转移到较小的模型中的技术。其主要目的是在保持模型性能的同时，减少模型的大小和计算资源需求。通过蒸馏技术，较小的模型可以在推理时更高效地运行，适用于资源受限的环境。

蒸馏过程通常包括以下几个步骤：

# 训练教师模型：首先训练一个大型且性能优越的教师模型。
# 生成[[软标签|大语言模型软标签]]：使用教师模型对训练数据进行预测，生成软目标 (soft targets) ，这些目标包含了教师模型的概率分布信息。
# 训练学生模型：使用软目标 (soft targets) 和原始训练数据 (hard targets) 来训练较小的学生模型，使其能够模仿教师模型的行为。 这种方法不仅可以提高模型的效率，还可以在某些情况下提高模型的泛化能力。

